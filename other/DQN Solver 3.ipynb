{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2f9ef4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from collections import deque, namedtuple\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import itertools\n",
    "import random\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fedbe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7993ebec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "443d945f",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 8\n",
    "k = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c140e5",
   "metadata": {},
   "source": [
    "# Environment\n",
    "This class describes the $N$-Queen environment and provides helper methods relating to it. The board is represented in `row major` representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "941cc35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NQueenEnv:\n",
    "    def __init__(self, n:int, k:int):\n",
    "        self.n = n\n",
    "        self.k = k\n",
    "        self._reset() # Initializes empty board\n",
    "        \n",
    "    def _reset(self):\n",
    "        \"\"\"\n",
    "            Sets the board to a matrix of zeros, from this a random k-queen partial n-queen solution can be set\n",
    "        \"\"\"\n",
    "        self.board = np.zeros(self.n*self.n)\n",
    "        self.rows, self.cols, self.diags, self.anti_diags = set(), set(), set(), set()\n",
    "        \n",
    "    def reset(self) -> np.array:\n",
    "        \"\"\"\n",
    "            Resets board with new partial N-Queens configuration\n",
    "        \"\"\"        \n",
    "        has_set = False\n",
    "        while not has_set:\n",
    "            self._reset() # resets board and line sets\n",
    "            num_set = 0\n",
    "            while num_set < self.k:\n",
    "                if not self.get_avail_squares(): break\n",
    "                action = self.sample_action()\n",
    "                self._perform_action(action)\n",
    "                \n",
    "                num_set += 1\n",
    "                \n",
    "            has_set = num_set == self.k\n",
    "    \n",
    "        return self.board # 1D array -> partial config\n",
    "    \n",
    "    def _perform_action(self, action:int):\n",
    "        \"\"\"\n",
    "        Performs action i.e. places queen on square (action//n, action (mod n))\n",
    "        \"\"\"\n",
    "        row,col = action//self.n, action%self.n\n",
    "        self.rows.add(row)\n",
    "        self.cols.add(col)\n",
    "        self.diags.add(col-row)\n",
    "        self.anti_diags.add(col+row)\n",
    "        \n",
    "        self.board[action] = 1\n",
    "        \n",
    "    def get_avail_squares(self) -> List[int]:\n",
    "        \"\"\"\n",
    "        Finds all available squares in (x,y) format\n",
    "        \"\"\"\n",
    "        avail = []\n",
    "        for i,j in itertools.product(range(self.n), range(self.n)):\n",
    "            if i in self.rows or j in self.cols or j-i in self.diags or j+i in self.anti_diags: continue\n",
    "            avail.append((i,j))\n",
    "        return avail\n",
    "    \n",
    "    def sample_action(self) -> int:\n",
    "        \"\"\"\n",
    "        Returns a random action to take i.e. a random available square\n",
    "        \"\"\"\n",
    "        row, col = random.sample(self.get_avail_squares(), 1)[0]\n",
    "        return self.n * row + col\n",
    "    \n",
    "    @staticmethod\n",
    "    def step(state, action:int) -> tuple:\n",
    "        \"\"\"\n",
    "            Performs action on the board, assumes that the action is valid\n",
    "        \"\"\"\n",
    "        avail = self.get_avail_squares()\n",
    "        self._perform_action(action)\n",
    "        terminate = len(self.rows) == self.n or len(avail) == 0\n",
    "        reward = len(avail)/self.n\n",
    "        return (self.board.copy(), reward, terminate) # new_state, reward, teminated\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_valid_mask(state):\n",
    "        rows,cols,diags,anti_diags = set(), set(), set(), set()\n",
    "        for i, j in itertools.product(range(N), range(N)):\n",
    "            if state[N*i + j] == 0: continue\n",
    "            rows.add(i)\n",
    "            cols.add(j)\n",
    "            diags.add(j-i)\n",
    "            anti_diags.add(j+i)\n",
    "        \n",
    "        mask = [0] * N**2\n",
    "        for i,j in itertools.product(range(N), range(N)):\n",
    "            if i in rows or j in cols or j-i in diags or j+i in anti_diags: continue\n",
    "            mask[i*N + j] = 1\n",
    "        \n",
    "        return np.asarray(mask)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_sample_action(state):\n",
    "        mask = NQueenEnv.get_valid_mask(state)\n",
    "        valid_actions = [i for i in range(N*N) if mask[i]]\n",
    "        return random.sample(valid_actions, 1)[0]\n",
    "    \n",
    "    def display(self, fontsize:int=10):\n",
    "        matrix = np.zeros((self.n, self.n), dtype=int)\n",
    "        for i in range(self.n**2):\n",
    "            matrix[i//self.n][i%self.n] = int(self.board[i])\n",
    "        \n",
    "        n = matrix.shape[0]\n",
    "        # Create a chess board (n x n) pattern\n",
    "        board = np.zeros_like(matrix)\n",
    "        board[1::2, ::2] = 1\n",
    "        board[::2, 1::2] = 1\n",
    "\n",
    "        cmap = ListedColormap(['#769656', '#eeeed2'])\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(board, cmap=cmap, interpolation='nearest')\n",
    "\n",
    "        # Place queens based on matrix\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                if matrix[i, j] == 1:\n",
    "                    ax.text(j, i, '♛', fontsize=fontsize, ha='center', va='center', color='black' if board[i, j] else 'white')\n",
    "\n",
    "        # Hide the axes\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e22e34d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.NQueenEnv at 0x1c31442cbe0>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = NQueenEnv(N, k)\n",
    "env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "990fae04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAL+ElEQVR4nO3dXWjd933H8a9s68n2OZIcK8aO1TgJeVhoEpLSQlJ61TkXbUgXQqipA4X0orlLPfDwhaG9cKhhhF4Mtrv21m1Jr+ZuJbBmxIWZhM5NNlLqNg9VrCWOmW0dOYrsRmcXaz/MBS/yiXT+Enq9Lo/+4A+/C735+Y84A91ut1sAUFUbmh4AwOohCgCEKAAQogBAiAIAIQoAhCgAEJuW8tDi4mLNzMxUq9WqgYGBld4EwDLrdrvV6XRq165dtWHDte8DS4rCzMxMTU1NLds4AJoxPT1du3fvvubPlxSFVqtVVVVPP/tIDY8MLs+yPjnw+MGmJ/Tke8//bdMTeubM+8t5999aPPNO51Ldc8/e/D6/liVF4U//ZTQ8MljDo2srCu321qYn9GStnfP/5cz7y3n331o986r62FcAXjQDEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIjCOrRxw6aaaE02PQNYhURhHXn4c1+te297sB644wv1za98u1qbx+vJhw/UlpH//0s3gPVjSV+yw9o2OrSldtwwVVf+cLnaWybq5dd/XtvHd9Zid7G2tXdUa/N4jW3dXjPn3mx6KtAwN4V14M6b76/9e5+pU6dP1Lb2jhoZGq2hwZFqb56o1944Wffd/vn60oP7m54JrAKisA6cOn2iXnr1p/XBh3N1++57anhotIYHR+rWXXfX+c7ZGtw4VD84/t2mZwKrgCisExc679eenXfWtvaOmhy/qYb+GIXFxcUaHhqtjxY/anoisAp4p7BO/Gb6V/W1vd+q+YW5+vQtn62RwdHaNXlLdatbr/z6xabnAauEm8I68eHl+ZpoTdbI0Oa6a88DddONt9aWkVbd9an7a/q9003PA1YJN4V15Oz5M/XaGyev+mxybGd1G9oDrD6isI5MtCZr6sbbrvps08bBhtYAq5EorCNz8xfqzJ/9LcLE1u0NrQFWI1FYR75//GjTE4BVzotmAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQDiur557cDjB6vd3rpSW1bE0WNHmp7Qk0P7Djc9oWfOvL+cd/+txTNfmL+ypOfcFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAIiBbrfb/biHZmdna2xsrJ557rEaHh3sx65lc2jf4aYn9OTosSNNT+iZM+8v591/a/HMZ2fnas+eh+rixYvVbrev+ZybAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAMSm63n4wOMHq93eulJbVsTRY0eantCTQ/sONz2hZ868v5x3/63FM1+Yv7Kk59wUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFD6BjRs21URrsukZAMtGFHrw8Oe+Wvfe9mA9cMcX6ptf+Xa1No/Xkw8fqC0jraanAXwi1/V1nOvd6NCW2nHDVF35w+Vqb5mol1//eW0f31mL3cXa1t5Rrc3jNbZ1e82ce7PpqQA9cVO4DnfefH/t3/tMnTp9ora1d9TI0GgNDY5Ue/NEvfbGybrv9s/Xlx7c3/RMgJ6JwnU4dfpEvfTqT+uDD+fq9t331PDQaA0PjtStu+6u852zNbhxqH5w/LtNzwTomShcpwud92vPzjtrW3tHTY7fVEN/jMLi4mIND43WR4sfNT0RoGfeKVyn30z/qr6291s1vzBXn77lszUyOFq7Jm+pbnXrlV+/2PQ8gE/ETeE6fXh5viZakzUytLnu2vNA3XTjrbVlpFV3fer+mn7vdNPzAD4RN4UenD1/pl574+RVn02O7axuQ3sAloso9GCiNVlTN9521WebNg42tAZg+YhCD+bmL9SZP/tbhImt2xtaA7B8RKEH3z9+tOkJACvCi2YAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAGKg2+1+7PfNz87O1tjYWD3z3GM1PLq2vov40L7DTU/oydFjR5qe0DNn3l/Ou//W4pnPzs7Vnj0P1cWLF6vdbl/zOTcFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBYBVYmHhcv3+92ca3SAKAA179tm/q5/85J/rRz/6x3rkkafq3Xffr69//a/r3Ln/7vuWTX3/FwGoqqoLF2br9ddP18jIcL377vv15JOP1e9+93Zt3Lih3nrrnTp79lydOfNu3Xff3X3b5KYA0JAXXnipvvGNv6knnvhyvf32O9XpzNWlSx/Ue++dq0cf/ct6/vl/qu9853t93SQKAA154okv19NPP1nj42P14ov/Vp3Opbp06YM6ceLluvnmm2p+fqF++MO/7+smUQBo0NTUrjp58t/rrbem6/TpN2tu7oP6xS9eqQ0bNtbc3KUaGhrs6x7vFAAa9MUvPlRPPXWwxsfbdfz4v1Snc6leffX1GhgYqP37/6rve9wUABrUbrdqenqmOp1L9bOf/WudOvWfdf78xXrhhZfqM5+5p+973BQAGnbHHbfWo4/uveqz3/727RoYGOj7FlEAaNj09Ez98pf/cdVnCwuXG9kiCgANm5y8oe699y+u+mx6+r8a2SIKAA378Y//oekJ4UUzACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgBxXd+8duDxg9Vub12pLSvi6LEjTU/oyaF9h5ue0DNn3l/Ou//W4pkvzF9Z0nNuCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAMRAt9vtftxDs7OzNTY2Vs8891gNjw72Y9eyObTvcNMTenL02JGmJ/TMmfeX8+6/tXjms7NztWfPQ3Xx4sVqt9vXfM5NAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAGLT9Tx84PGD1W5vXaktK+LosSNNT+jJoX2Hm57QM2feX867/9bimS/MX1nSc24KAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAsWkpD3W73aqq6nQureiYlbAwf6XpCT2ZnZ1rekLPnHl/Oe/+W4tnvvDh/27+0+/zaxnoftwTVfXOO+/U1NTU8iwDoDHT09O1e/fua/58SVFYXFysmZmZarVaNTAwsKwDAVh53W63Op1O7dq1qzZsuPabgyVFAYD1wYtmAEIUAAhRACBEAYAQBQBCFAAIUQAg/geLph0Jr4/1UwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 1.75, False)\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "env.display()\n",
    "plt.show()\n",
    "action = env.sample_action()\n",
    "print(action, env.step(action))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848aa5d5",
   "metadata": {},
   "source": [
    "# Model\n",
    "Note that both a `policy net` and a `target net` neural net is created.\n",
    "\n",
    "The `policy_net` is essentially the regular NN trying to estimate the Q-values for each action (expected reward | action), but the Q-values will be updated quite frequently leading to unstable training.\n",
    "\n",
    "This is where the `target_net` comes in, as periodically the `policy_net` weights are copied to `target_net`. The fixed values provided by `target_net` is used to stabilize the training of the `policy_net`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "23477875",
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "06e7920c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, n_observations, n_actions):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(n_observations, 512)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.fc3 = nn.Linear(512, n_actions)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "42d7550c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DQN(\n",
       "  (fc1): Linear(in_features=64, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (fc3): Linear(in_features=512, out_features=64, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get number of actions from gym action space\n",
    "n_actions = N*N\n",
    "# Get the number of state observations\n",
    "state = env.reset()\n",
    "n_observations = len(state)\n",
    "\n",
    "policy_net = DQN(n_observations, n_actions).to(device)\n",
    "target_net = DQN(n_observations, n_actions).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "policy_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b990958d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0636,  0.0084, -0.0258, -0.0035,  0.0085, -0.0104, -0.0011, -0.0377,\n",
       "         0.0228, -0.0167,  0.0281, -0.0807, -0.0358,  0.0373, -0.0506, -0.0096,\n",
       "        -0.0422, -0.0620, -0.0047, -0.0237,  0.0499, -0.0452,  0.0024, -0.0135,\n",
       "        -0.0173,  0.0285, -0.0033,  0.0051, -0.0150,  0.0079,  0.0462, -0.0611,\n",
       "        -0.0040, -0.0008,  0.0049, -0.0191, -0.0607, -0.0535, -0.0425, -0.0284,\n",
       "        -0.0297,  0.0267, -0.0252, -0.0369, -0.0382, -0.0440, -0.0041,  0.0036,\n",
       "        -0.0510, -0.0453,  0.0161,  0.0217, -0.0121, -0.0526,  0.0052, -0.0124,\n",
       "         0.0441, -0.0286, -0.0037,  0.0153, -0.0641,  0.0184, -0.0136,  0.0612],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = env.reset()\n",
    "result = policy_net(torch.as_tensor(state, dtype=torch.float32))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "24ba26d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.max(0)[1].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "39d53487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[63]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.max(0).indices.view(1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977e8720",
   "metadata": {},
   "source": [
    "# Training\n",
    "We're doing $\\epsilon$-greedy method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46899cfd",
   "metadata": {},
   "source": [
    "### Hyperparameters and utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6b755942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for training\n",
    "\n",
    "BATCH_SIZE = 128 # BATCH_SIZE is the number of transitions sampled from the replay buffer\n",
    "GAMMA = 0.99 # GAMMA is the discount factor\n",
    "EPS_START = 0.9 # EPS_START is the starting value of epsilon\n",
    "EPS_END = 0.05 # EPS_END is the final value of epsilon\n",
    "EPS_DECAY = 1000 # EPS_DECAY controls the rate of exponential decay of epsilon, higher means a slower decay\n",
    "TAU = 0.005 # TAU is the update rate of the target network\n",
    "LR = 1e-4 # LR is the learning rate of the ``AdamW`` optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bf36a67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(policy_net.parameters(), lr=LR, amsgrad=True)\n",
    "memory = ReplayMemory(10000)\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    \n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            infered_policy = policy_net(state)\n",
    "            # Mask out invalid actions\n",
    "            mask = torch.as_tensor(env.get_valid_mask(state))\n",
    "            infered_policy *= mask\n",
    "            return infered_policy.max(0).indices.view(1, 1)\n",
    "            \n",
    "    else:\n",
    "        return torch.tensor([[env.get_sample_action(state)]], device=device, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "81f24483",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[9]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = torch.as_tensor(env.reset(), dtype=torch.float32)\n",
    "env.display(fontsize=20)\n",
    "plt.show()\n",
    "select_action(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "65ae3c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation). This converts batch-array of Transitions\n",
    "    # to Transition of batch-arrays.\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    # (a final state would've been the one after which simulation ended)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken. These are the actions which would've been taken\n",
    "    # for each batch state according to policy_net\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    # Expected values of actions for non_final_next_states are computed based\n",
    "    # on the \"older\" target_net; selecting their best reward with max(1).values\n",
    "    # This is merged based on the mask, such that we'll have either the expected\n",
    "    # state value or 0 in case the state was final.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    with torch.no_grad():\n",
    "        next_state_values[non_final_mask] = target_net(non_final_next_states).max(1).values\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Compute Huber loss\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    # In-place gradient clipping\n",
    "    torch.nn.utils.clip_grad_value_(policy_net.parameters(), 100)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86daf59a",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "58d5b00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_durations = []\n",
    "\n",
    "\n",
    "def plot_durations(show_result=False):\n",
    "    plt.figure(1)\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    if show_result:\n",
    "        plt.title('Result')\n",
    "    else:\n",
    "        plt.clf()\n",
    "        plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    # Take 100 episode averages and plot them too\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    if not show_result:\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "    else:\n",
    "        display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5044a7fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26091846f4ae4e23928345f3748bb921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]]) tensor([[39]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]]) tensor([[4]])\n",
      "tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]]) tensor([[50]])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Sample larger than population or is negative",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [97], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(state, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32, device\u001b[38;5;241m=\u001b[39mdevice)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mcount():\n\u001b[1;32m----> 8\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[43mselect_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(state, action)\n\u001b[0;32m     10\u001b[0m     observation, reward, terminated \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action\u001b[38;5;241m.\u001b[39mitem())\n",
      "Cell \u001b[1;32mIn [93], line 21\u001b[0m, in \u001b[0;36mselect_action\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m infered_policy\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_sample_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m]], device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n",
      "Cell \u001b[1;32mIn [78], line 93\u001b[0m, in \u001b[0;36mNQueenEnv.get_sample_action\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m     91\u001b[0m mask \u001b[38;5;241m=\u001b[39m NQueenEnv\u001b[38;5;241m.\u001b[39mget_valid_mask(state)\n\u001b[0;32m     92\u001b[0m valid_actions \u001b[38;5;241m=\u001b[39m [i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N\u001b[38;5;241m*\u001b[39mN) \u001b[38;5;28;01mif\u001b[39;00m mask[i]]\n\u001b[1;32m---> 93\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalid_actions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\random.py:482\u001b[0m, in \u001b[0;36mRandom.sample\u001b[1;34m(self, population, k, counts)\u001b[0m\n\u001b[0;32m    480\u001b[0m randbelow \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_randbelow\n\u001b[0;32m    481\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m k \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m n:\n\u001b[1;32m--> 482\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSample larger than population or is negative\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    483\u001b[0m result \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m k\n\u001b[0;32m    484\u001b[0m setsize \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m21\u001b[39m        \u001b[38;5;66;03m# size of a small set minus size of an empty list\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Sample larger than population or is negative"
     ]
    }
   ],
   "source": [
    "num_episodes = 600\n",
    "    \n",
    "for i_episode in tqdm(range(num_episodes)):\n",
    "    # Initialize the environment and get its state\n",
    "    state = env.reset()\n",
    "    state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "    for t in itertools.count():\n",
    "        action = select_action(state[0])\n",
    "        print(state, action)\n",
    "        observation, reward, terminated = env.step(action.item())\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "        done = terminated\n",
    "\n",
    "        if terminated:\n",
    "            next_state = None\n",
    "        else:\n",
    "            next_state = torch.tensor(observation, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "\n",
    "        # Store the transition in memory\n",
    "        memory.push(state, action, next_state, reward)\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        # Perform one step of the optimization (on the policy network)\n",
    "        optimize_model()\n",
    "\n",
    "        # Soft update of the target network's weights\n",
    "        # θ′ ← τ θ + (1 −τ )θ′\n",
    "        target_net_state_dict = target_net.state_dict()\n",
    "        policy_net_state_dict = policy_net.state_dict()\n",
    "        for key in policy_net_state_dict:\n",
    "            target_net_state_dict[key] = policy_net_state_dict[key]*TAU + target_net_state_dict[key]*(1-TAU)\n",
    "        target_net.load_state_dict(target_net_state_dict)\n",
    "\n",
    "        if done:\n",
    "            episode_durations.append(t + 1)\n",
    "            break\n",
    "\n",
    "print('Complete')\n",
    "plot_durations(show_result=True)\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4b04cb",
   "metadata": {},
   "source": [
    "# Inferrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07812565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_state_history(state_history, n):\n",
    "    fig, axs = plt.subplots(1, len(state_history), figsize=(len(state_history)*4, 4))\n",
    "    if len(state_history) == 1:  # If there's only one state, axs is not an array\n",
    "        axs = [axs]\n",
    "        \n",
    "    for ax, state in zip(axs, state_history):\n",
    "        matrix = state.reshape((n, n))  # Assuming state is a flat array\n",
    "        board = np.zeros_like(matrix)\n",
    "        board[1::2, ::2] = 1\n",
    "        board[::2, 1::2] = 1\n",
    "        cmap = ListedColormap(['#769656', '#eeeed2'])\n",
    "        ax.imshow(board, cmap=cmap, interpolation='nearest')\n",
    "        \n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                if matrix[i, j] == 1:\n",
    "                    ax.text(j, i, '♛', fontsize=10, ha='center', va='center', color='black' if board[i, j] else 'white')\n",
    "        \n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f3e0c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_queen(env):\n",
    "    state = env.board\n",
    "    state = torch.as_tensor(state, dtype=torch.float32).unsqueeze(0)\n",
    "    print(state)\n",
    "    with torch.no_grad():\n",
    "        infered_policy = policy_net(state)\n",
    "        # Mask out invalid actions\n",
    "        mask = torch.as_tensor(env.get_valid_mask())\n",
    "        infered_policy *= mask\n",
    "        action = infered_policy.max(1).indices.view(1, 1).item()\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f7a8e660",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[22]]) 22\n",
      "[array([0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 1., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0.]), array([1., 0., 0., 0., 0., 0., 0., 0.])]\n",
      "tensor([[41]]) 41\n",
      "[array([0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 1., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 1., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0.]), array([1., 0., 0., 0., 0., 0., 0., 0.])]\n",
      "tensor([[2]]) 2\n",
      "[array([0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 1., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 1., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0.]), array([0., 1., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0.]), array([1., 0., 0., 0., 0., 0., 0., 0.])]\n"
     ]
    }
   ],
   "source": [
    "state_history = []\n",
    "\n",
    "# Random k-queen partial config\n",
    "state = env.reset()\n",
    "state_history.append(state.copy())\n",
    "\n",
    "# completions\n",
    "while len(env.get_avail_squares()):\n",
    "    action = select_action(torch.tensor(state, dtype=torch.float32))\n",
    "    \n",
    "    print(action, action.item())\n",
    "    print([state[N*i:N*(i+1)] for i in range(N)])\n",
    "    action = action.item()\n",
    "    env._perform_action(action)\n",
    "    state = env.board.copy()\n",
    "    state_history.append(state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d8820836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1600x400 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_state_history(state_history, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3747c08e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b199ea62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
